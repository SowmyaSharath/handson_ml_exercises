{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Number 3 - California Housing Dataset- SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collate all import statements here\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from zlib import crc32\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8) (4128, 8) (16512,) (4128,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       20640 non-null  float64\n",
      " 1   1       20640 non-null  float64\n",
      " 2   2       20640 non-null  float64\n",
      " 3   3       20640 non-null  float64\n",
      " 4   4       20640 non-null  float64\n",
      " 5   5       20640 non-null  float64\n",
      " 6   6       20640 non-null  float64\n",
      " 7   7       20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Fetch the Data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "X = housing['data']\n",
    "y=housing['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "print(pd.DataFrame(X).info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:- Looking at the Data it is very clear that it is a cleaned data without any null values. So I will not be performing any Imputations unlike the exercises on the same dataset in Chapter 2. Also, in the chapter 2 dataset we had an Ocean Proximity column which took categorical values. That seems to be missing here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8)\n",
      "(16512,)\n",
      "Training Error is  0.31526557267334276\n",
      "[-0.28756067 -0.31107866 -0.34830193 -0.3389931  -0.35599795 -0.33327574\n",
      " -0.30949294 -0.34356807 -0.31222674 -0.34812683]\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "])\n",
    "transformed_data = num_pipeline.fit_transform(X_train)\n",
    "svregressor = SVR()\n",
    "print(transformed_data.shape)\n",
    "print(y_train.shape)\n",
    "svregressor.fit(transformed_data,y_train)\n",
    "predictions = svregressor.predict(transformed_data)\n",
    "mse = mean_squared_error(predictions, y_train)\n",
    "print('Training Error is ', mse)\n",
    "\n",
    "scores = cross_val_score(svregressor, transformed_data, y_train,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "sqrt_scores = np.sqrt(-scores)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4128, 8)\n",
      "Testing Error is  0.4297331594746025\n"
     ]
    }
   ],
   "source": [
    "transformed_test_data = num_pipeline.fit_transform(X_test)\n",
    "print(transformed_test_data.shape)\n",
    "predictions = svregressor.predict(transformed_test_data)\n",
    "mse = mean_squared_error(predictions, y_test)\n",
    "print('Testing Error is ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:- We will do a Grid SearchCV to see which kernel performs best and then finetune hyperparameters on the selected kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear'}\n",
      "-1.41528661571761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Optimise and find the best hyper params\n",
    "\n",
    "param_grid = [\n",
    "    {},\n",
    "]\n",
    "grid_search_cv = GridSearchCV(svregressor,param_grid,scoring=\"neg_mean_squared_error\",cv=10,return_train_score=True)\n",
    "grid_search_cv.fit(transformed_data,y_train)\n",
    "\n",
    "#Exploring results from Grid Search CV\n",
    "print(grid_search_cv.best_params_)\n",
    "print(grid_search_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:- Looking at the above output, it is clear that Linear kernel gives us a good accuracy. So let us do a randomisedsearchCV with different hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Optimise and find the best hyper params\n",
    "\n",
    "param_grid = [\n",
    "    {\"C\" :[1,10,50,75,100], \"epsilon\":[0.001,0.01,0.1,1],\"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"]},\n",
    "]\n",
    "rand_search_cv = RandomizedSearchCV(svregressor,param_grid,scoring=\"neg_mean_squared_error\",cv=10,return_train_score=True)\n",
    "rand_search_cv.fit(transformed_data,y_train)\n",
    "\n",
    "#Exploring results from Grid Search CV\n",
    "print(rand_search_cv.best_params_)\n",
    "print(rand_search_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Randomised Search and Grid Search we can conclude that the {'kernel': 'linear'}, {'epsilon': 1, 'C': 10} give the best values. So it will be good idea to train the model with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8)\n",
      "(16512,)\n",
      "Training Error is  0.5520495011879758\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "])\n",
    "transformed_data = num_pipeline.fit_transform(X_train)\n",
    "svregressor = SVR(kernel='linear',C=10, epsilon=1)\n",
    "print(transformed_data.shape)\n",
    "print(y_train.shape)\n",
    "svregressor.fit(transformed_data,y_train)\n",
    "predictions = svregressor.predict(transformed_data)\n",
    "mse = mean_squared_error(predictions, y_train)\n",
    "print('Training Error is ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4128, 8)\n",
      "Testing Error is  0.6050316603651753\n"
     ]
    }
   ],
   "source": [
    "transformed_test_data = num_pipeline.fit_transform(X_test)\n",
    "print(transformed_test_data.shape)\n",
    "predictions = svregressor.predict(transformed_test_data)\n",
    "mse = mean_squared_error(predictions, y_test)\n",
    "print('Testing Error is ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we look at the Training and Test results we can conclude that marginally plain SVR (kernel = rbf, c=1.0 and epsilon=0.01) gives better results and we will use that as the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - MNIST Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROJECT_ROOT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b3347625759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plotting and saving the digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mIMAGES_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_ROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHAPTER_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtight_layout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGES_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfig_extension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PROJECT_ROOT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting and saving the digits\n",
    "import matplotlib.pyplot as plt\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.figure(figsize=(9,9))\n",
    "example_images = X[:100]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "save_fig(\"more_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
